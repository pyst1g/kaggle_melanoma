{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkQEDQA44qlC"
   },
   "source": [
    "# Melanoma classification with PyTorch Lightning\n",
    "\n",
    "Using EfficientNet on PyTorch Lightning, with its amazing hardware agnostic and mixed precision implementation.\n",
    "\n",
    "This is still work in progress, so please bear with me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftZsAlKR4qlF"
   },
   "outputs": [],
   "source": [
    "fold_number = 1\n",
    "seed  = 66\n",
    "debug = False\n",
    "tta   = 2 if debug else 20\n",
    "\n",
    "batch_size = {\n",
    "    'tpu': 10, # x8\n",
    "    'gpu': 22, # 10 without AMP\n",
    "    'cpu': 4,\n",
    "}\n",
    "\n",
    "arch = 'efficientnet-b5'\n",
    "resolution = 456  # orignal res for B5\n",
    "input_res  = 512\n",
    "\n",
    "lr = 8e-6   # * batch_size\n",
    "weight_decay = 2e-5\n",
    "pos_weight   = 3.2\n",
    "label_smoothing = 0.03\n",
    "\n",
    "max_epochs = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnEoyD1a4qlO"
   },
   "source": [
    "# Why PyTorch Lightning?\n",
    "Lightning is simply organized PyTorch code. There's NO new framework to learn.\n",
    "For more details about Lightning visit the repo:\n",
    "\n",
    "https://github.com/PyTorchLightning/pytorch-lightning\n",
    "\n",
    "- Run on CPU, GPU clusters or TPU, without any code changes\n",
    "- Transparent use of AMP (automatic mixed precision)\n",
    "\n",
    "![lightning structure](https://raw.githubusercontent.com/PyTorchLightning/pytorch-lightning/master/docs/source/_images/lightning_module/pt_to_pl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7QSur04qlR"
   },
   "source": [
    "# Install modules\n",
    "\n",
    "Update PyTorch to enable its native support to Mixed Precision or XLA for TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "id": "_lmyKFye4qlT",
    "outputId": "a008eca4-4ec3-4ac7-a1a8-7f72cfa3c337"
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "if 'TPU_NAME' in os.environ.keys():\n",
    "    try:\n",
    "        import torch_xla\n",
    "    except:\n",
    "        # XLA powers the TPU support for PyTorch\n",
    "        !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "        !python pytorch-xla-env-setup.py --apt-packages libomp5 libopenblas-dev\n",
    "else:\n",
    "    # Update PyTorch to enable its native support to Mixed Precision\n",
    "    !pip install --pre torch==1.7.0.dev20200701+cu101 torchvision==0.8.0.dev20200701+cu101 -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n",
    "\n",
    "!pip install -U pip albumentations==0.4.5 PyYAML pytorch-lightning==0.8.5 efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRdfuFiR4qlf"
   },
   "source": [
    "# Hardware lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "t9FS-xGM4qlh",
    "outputId": "5802bc07-8b6e-4254-ac49-2139d11911f8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "num_workers = 2  # os.cpu_count()\n",
    "gpus = 1 if torch.cuda.is_available() else None\n",
    "\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    tpu_cores = 8 #xm.xrt_world_size()\n",
    "except:\n",
    "    tpu_cores = None\n",
    "\n",
    "if isinstance(batch_size, dict):\n",
    "    if tpu_cores:\n",
    "        batch_size = batch_size['tpu']\n",
    "        lr *= tpu_cores\n",
    "        num_workers = 1\n",
    "    elif gpus:\n",
    "        batch_size = batch_size['gpu']\n",
    "        # support for free Colab GPU's\n",
    "        if 'K80' in torch.cuda.get_device_name():\n",
    "            batch_size = batch_size//3\n",
    "        elif 'T4' in torch.cuda.get_device_name():\n",
    "            batch_size = int(batch_size * 0.66)\n",
    "    else:\n",
    "        batch_size = batch_size['cpu']\n",
    "\n",
    "lr *= batch_size\n",
    "\n",
    "dict(\n",
    "    num_workers=num_workers,\n",
    "    tpu_cores=tpu_cores,\n",
    "    gpus=gpus,\n",
    "    batch_size=batch_size,\n",
    "    lr=lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fa--zHZ64qln"
   },
   "source": [
    "# Automatic Mixed Precision\n",
    "\n",
    "NVIDIA Apex is required only prior to PyTorch 1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "2jNntNJb4qln"
   },
   "outputs": [],
   "source": [
    "# check for torch's native mixed precision support (pt1.6+)\n",
    "if gpus and not hasattr(torch.cuda, \"amp\"):\n",
    "    try:\n",
    "        from apex import amp\n",
    "    except:\n",
    "        !git clone https://github.com/NVIDIA/apex  nv_apex\n",
    "        !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./nv_apex\n",
    "        from apex import amp\n",
    "    # with PyTorch Lightning all you need to do now is set precision=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaoinaAu4qlu"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "id": "UFXXIDJt4qlv",
    "outputId": "b5e99e4c-016c-440c-e2f4-c3ed45ba50eb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from skimage import io\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from glob import glob\n",
    "import sklearn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(seed*6 + fold_number)\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeM18dHg4qlz"
   },
   "source": [
    "# Dataset\n",
    "\n",
    "We will be using @shonenkov dataset with external data: https://www.kaggle.com/shonenkov/melanoma-merged-external-data-512x512-jpeg \n",
    "\n",
    "thank you @shonenkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "MQ0g7uTd4ql0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path, image_ids, labels=None, transforms=None):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = cv2.imread(f'{self.path}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=image)\n",
    "            image  = sample['image']\n",
    "\n",
    "        label = self.labels[idx] if self.labels is not None else 0.5\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlBehFHZ4ql4"
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "9We_dtmL4ql6"
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "            A.JpegCompression(p=0.5),\n",
    "            A.Rotate(limit=80, p=1.0),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(),\n",
    "                A.GridDistortion(),\n",
    "                A.IAAPiecewiseAffine(),\n",
    "            ]),\n",
    "            A.RandomSizedCrop(min_max_height=(int(resolution*0.7), input_res),\n",
    "                              height=resolution, width=resolution, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.GaussianBlur(p=0.3),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(),   \n",
    "                A.HueSaturationValue(),\n",
    "            ]),\n",
    "            A.Cutout(num_holes=8, max_h_size=resolution//8, max_w_size=resolution//8, fill_value=0, p=0.3),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.CenterCrop(height=resolution, width=resolution, p=1.0),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_tta_transforms():\n",
    "    return A.Compose([\n",
    "            A.JpegCompression(p=0.5),\n",
    "            A.RandomSizedCrop(min_max_height=(int(resolution*0.9), int(resolution*1.1)),\n",
    "                              height=resolution, width=resolution, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.Transpose(p=0.5),\n",
    "            A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6K-p9nPl4ql-"
   },
   "source": [
    "# Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dq3S8RAF4ql_",
    "outputId": "00122522-4e2b-4e79-adcb-6501fea3ff78"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'\n",
    "TRAIN_ROOT_PATH = f'{DATA_PATH}/512x512-dataset-melanoma/512x512-dataset-melanoma'\n",
    "TEST_ROOT_PATH = f'{DATA_PATH}/512x512-test/512x512-test'\n",
    "\n",
    "df_folds = pd.read_csv(f'{DATA_PATH}/folds.csv', index_col='image_id',\n",
    "                       usecols=['image_id', 'fold', 'target'], dtype={'fold': np.byte, 'target': np.byte})\n",
    "\n",
    "_ = df_folds.groupby('fold').target.hist(alpha=0.4)\n",
    "df_folds.groupby('fold').target.mean().to_frame('ratio').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3h2Zcdod4qmE"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(f'../input/siim-isic-melanoma-classification/test.csv', index_col='image_name')\n",
    "\n",
    "if debug:\n",
    "    df_folds = df_folds.sample(batch_size * 80)\n",
    "\n",
    "df_folds = df_folds.sample(frac=1.0, random_state=seed*6+fold_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5i8UhuvM4qmJ",
    "outputId": "c0ea1e24-01ca-4660-af87-df919cdc884c"
   },
   "outputs": [],
   "source": [
    "ds_train = ImageDataset(\n",
    "    path=TRAIN_ROOT_PATH,\n",
    "    image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
    "    labels=df_folds[df_folds['fold'] != fold_number].target.values,\n",
    "    transforms=get_train_transforms(),\n",
    ")\n",
    "\n",
    "ds_val = ImageDataset(\n",
    "    path=TRAIN_ROOT_PATH,\n",
    "    image_ids=df_folds[df_folds['fold'] == fold_number].index.values,\n",
    "    labels=df_folds[df_folds['fold'] == fold_number].target.values,\n",
    "    transforms=get_valid_transforms(),\n",
    ")\n",
    "\n",
    "ds_test = ImageDataset(\n",
    "    path=TEST_ROOT_PATH,\n",
    "    image_ids=df_test.index.values,\n",
    "    transforms=get_tta_transforms(),\n",
    ")\n",
    "\n",
    "del df_folds\n",
    "len(ds_train), len(ds_val), len(ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqfK4rxh4qmO"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "vMgS0GCj4qmP"
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "from pytorch_lightning.metrics.classification import AUROC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.net = EfficientNet.from_pretrained(arch, advprop=True)\n",
    "        self.net._fc = nn.Linear(in_features=self.net._fc.in_features, out_features=1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            max_lr=lr,\n",
    "            epochs=max_epochs,\n",
    "            optimizer=optimizer,\n",
    "            steps_per_epoch=int(len(ds_train) / batch_size),\n",
    "            pct_start=0.1,\n",
    "            div_factor=10,\n",
    "            final_div_factor=100,\n",
    "            base_momentum=0.90,\n",
    "            max_momentum=0.95,\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def step(self, batch):\n",
    "        # return batch loss\n",
    "        x, y  = batch\n",
    "        y_hat = self(x).flatten()\n",
    "        y_smo = y.float() * (1 - label_smoothing) + 0.5 * label_smoothing\n",
    "        loss  = F.binary_cross_entropy_with_logits(y_hat, y_smo.type_as(y_hat),\n",
    "                                                   pos_weight=torch.tensor(pos_weight))\n",
    "        return loss, y, y_hat.sigmoid()\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # hardware agnostic training\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        acc = (y_hat.round() == y).float().mean().item()\n",
    "        tensorboard_logs = {'train_loss': loss, 'acc': acc}\n",
    "        return {'loss': loss, 'acc': acc, 'log': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        loss, y, y_hat = self.step(batch)\n",
    "        return {'val_loss': loss,\n",
    "                'y': y.detach(), 'y_hat': y_hat.detach()}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        y = torch.cat([x['y'] for x in outputs])\n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        auc = AUROC()(pred=y_hat, target=y) if y.float().mean() > 0 else 0.5 # skip sanity check\n",
    "        acc = (y_hat.round() == y).float().mean().item()\n",
    "        print(f\"Epoch {self.current_epoch} acc:{acc} auc:{auc}\")\n",
    "        tensorboard_logs = {'val_loss': avg_loss, 'val_auc': auc, 'val_acc': acc}\n",
    "        return {'avg_val_loss': avg_loss,\n",
    "                'val_auc': auc, 'val_acc': acc,\n",
    "                'log': tensorboard_logs}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, _ = batch\n",
    "        y_hat = self(x).flatten().sigmoid()\n",
    "        return {'y_hat': y_hat}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        y_hat = torch.cat([x['y_hat'] for x in outputs])\n",
    "        df_test['target'] = y_hat.tolist()\n",
    "        N = len(glob('submission*.csv'))\n",
    "        df_test.target.to_csv(f'submission{N}.csv')\n",
    "        return {'tta': N}\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(ds_train, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=True, shuffle=True, pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(ds_val, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=False, shuffle=False, pin_memory=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(ds_test, batch_size=batch_size, num_workers=num_workers,\n",
    "                          drop_last=False, shuffle=False, pin_memory=False)\n",
    "\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some training images\n",
    "import torchvision.utils as vutils\n",
    "batch, targets = next(iter(model.train_dataloader()))\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "_ = plt.imshow(vutils.make_grid(\n",
    "    batch[:16], nrow=8, padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0)))\n",
    "\n",
    "targets[:16].reshape([2, 8]) if len(targets) >= 16 else targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# # test the same images\n",
    "# with torch.no_grad():\n",
    "#     print(model(batch[:16]).reshape([len(targets)//8,8]).sigmoid())\n",
    "del batch; del targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1ib_IBN4qmS"
   },
   "source": [
    "# Train\n",
    "The Trainer automates the rest.\n",
    "\n",
    "Trains on 8 TPU cores, GPU or CPU - whatever is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # View logs life in tensorboard\n",
    "# Unfortunately broken again in the Kaggle notebooks :(\n",
    "# however, it still works nicely in Colab or locally :)\n",
    "\n",
    "# if gpus:\n",
    "#     !pip install -qU tensorboard-plugin-profile\n",
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "4AEUW-iB4qmT",
    "outputId": "49468221-86ef-4e7b-b627-7d51397fad08"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\"{epoch:02d}_{val_auc:.4f}\",\n",
    "                                                   save_top_k=1, monitor='val_auc', mode='max')\n",
    "trainer = pl.Trainer(\n",
    "    tpu_cores=tpu_cores,\n",
    "    gpus=gpus,\n",
    "    precision=16 if gpus else 32,\n",
    "    max_epochs=max_epochs,\n",
    "    num_sanity_val_steps=1 if debug else 0,\n",
    "    checkpoint_callback=checkpoint_callback,\n",
    "#     val_check_interval=0.25, # check validation 4 times per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# clean up gpu in case you are debugging \n",
    "import gc\n",
    "torch.cuda.empty_cache(); gc.collect()\n",
    "torch.cuda.empty_cache(); gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpASvAkY4qmb",
    "outputId": "ed7fc27d-3b35-4ca9-d479-b2318582d38c"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "apwpS9S94qmf"
   },
   "outputs": [],
   "source": [
    "# import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4WrS30T4qmj"
   },
   "source": [
    "# Submission\n",
    "Infer on test set using a simple random TTA (test-time augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for _ in range(tta):\n",
    "    trainer.test(ckpt_path='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HEluAlSiRsr"
   },
   "outputs": [],
   "source": [
    "# merge TTA\n",
    "submission = df_test[['target']]\n",
    "submission.target = 0.0\n",
    "for sub in glob('submission*.csv'):\n",
    "    submission.target += pd.read_csv(sub, index_col='image_name').target\n",
    "\n",
    "# min-max norm\n",
    "submission.target -= submission.target.min()\n",
    "submission.target /= submission.target.max()\n",
    "\n",
    "submission.to_csv(f'submission_fold{fold_number}.csv')\n",
    "\n",
    "submission.hist(bins=100, log=True, alpha=0.6)\n",
    "submission.target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_path = '../input/melanoma-neat-pytorch-lightning'\n",
    "!cp {folds_path}/*_fold*.csv .\n",
    "!cp {folds_path}/*.ckpt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_sub = pd.read_csv(f'{folds_path}/submission.csv', index_col='image_name')\n",
    "\n",
    "# incremental blend with equal weights for all folds\n",
    "submission.target += folds_sub.target * (fold_number + 4)\n",
    "submission.target /= (fold_number + 5)\n",
    "\n",
    "submission.to_csv('submission.csv')\n",
    "\n",
    "submission.hist(bins=100, log=True, alpha=0.6)\n",
    "submission.target.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "329ls2VE4qmu"
   },
   "outputs": [],
   "source": [
    "if not debug and gpus:\n",
    "    !rm nv_apex -rf\n",
    "!ls -sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
