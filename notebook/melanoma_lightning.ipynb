{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:56.362844Z",
     "start_time": "2020-08-05T05:42:54.326447Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "# from packages.lpproj_LPP import LocalityPreservingProjection\n",
    "from lpproj import LocalityPreservingProjection\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.logging import TensorBoardLogger\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "# from utils import *\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "now = datetime.now().strftime(\"%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:56.376801Z",
     "start_time": "2020-08-05T05:42:56.366872Z"
    }
   },
   "outputs": [],
   "source": [
    "fold_number = 0\n",
    "batch_size = 256\n",
    "use_external = True\n",
    "gpus = [0,1,2,3]\n",
    "\n",
    "\n",
    "ROOT_PATH = '..'\n",
    "DATA_PATH = f'{ROOT_PATH}/input/jpeg-melanoma-512x512/'\n",
    "EXT_DATA_PATH = f'{ROOT_PATH}/input/jpeg-isic2019-512x512/'\n",
    "TRAIN_ROOT_PATH = f'{DATA_PATH}/train'\n",
    "EXT_TRAIN_ROOT_PATH = f'{EXT_DATA_PATH}/train'\n",
    "TEST_ROOT_PATH = f'{DATA_PATH}/test'\n",
    "CKPT_PATH = f'{ROOT_PATH}/checkpoints/fold{fold_number}_{now}'\n",
    "LOG_PATH = f'{ROOT_PATH}/logs/fold{fold_number}_{now}'\n",
    "\n",
    "FEATURES = [\"sex\", \"age_approx\", \"width\", \"height\", \"anatom_site_general_challenge\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T02:11:44.633458Z",
     "start_time": "2020-07-30T02:11:44.629071Z"
    }
   },
   "source": [
    "#### data load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:56.891053Z",
     "start_time": "2020-08-05T05:42:56.380140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>fold</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ratio</th>\n",
       "      <td>0.08793</td>\n",
       "      <td>0.08749</td>\n",
       "      <td>0.086636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "fold         0        1         2\n",
       "ratio  0.08793  0.08749  0.086636"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = pd.read_csv(f'{DATA_PATH}/train.csv', index_col=\"image_name\")\n",
    "df_ext = pd.read_csv(f'{EXT_DATA_PATH}/train.csv', index_col=\"image_name\")\n",
    "\n",
    "df_train[\"data_path\"] = TRAIN_ROOT_PATH\n",
    "df_ext[\"data_path\"] = EXT_TRAIN_ROOT_PATH\n",
    "\n",
    "df_train = pd.concat([df_train, df_ext])\n",
    "df_train[\"fold\"] = df_train[\"tfrecord\"] %3\n",
    "\n",
    "df_train = df_train.drop(\"tfrecord\", axis=1)\n",
    "\n",
    "df_test = pd.read_csv(f'{DATA_PATH}/test.csv', index_col=\"image_name\")\n",
    "df_test[\"data_path\"] = f\"{DATA_PATH}/test\"\n",
    "\n",
    "_ = df_train.groupby('fold').target.hist(alpha=0.4)\n",
    "df_train.groupby('fold').target.mean().to_frame('ratio').T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tableデータの特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.235117Z",
     "start_time": "2020-08-05T05:42:56.894525Z"
    }
   },
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_train, df_test])\n",
    "df_concat[\"sex\"] = (df_concat[\"sex\"] ==\"male\")\n",
    "df_concat[\"age_approx\"] = df_concat[\"age_approx\"].fillna(df_concat[\"age_approx\"].mean())\n",
    "df_concat[\"anatom_site_general_challenge\"] = df_concat[\"anatom_site_general_challenge\"].fillna(\"unknown\")\n",
    "df_concat[\"anatom_site_general_challenge\"] = df_concat[\"anatom_site_general_challenge\"].map(dict(df_concat[\"anatom_site_general_challenge\"].value_counts()))\n",
    "df_concat[FEATURES] = (df_concat[FEATURES] - df_concat[FEATURES].mean()) / df_concat[FEATURES].std()\n",
    "\n",
    "df_train = df_concat.loc[df_train.index]\n",
    "df_test = df_concat.loc[df_test.index, df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.239209Z",
     "start_time": "2020-08-05T05:42:57.236738Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# DATA_PATH = '../input/melanoma-merged-external-data-512x512-jpeg'\n",
    "# TRAIN_ROOT_PATH = f'{DATA_PATH}/512x512-dataset-melanoma/512x512-dataset-melanoma'\n",
    "# TEST_ROOT_PATH = f'{DATA_PATH}/512x512-test/512x512-test'\n",
    "\n",
    "# df_folds = pd.read_csv(f'{DATA_PATH}/folds.csv', index_col='image_id',\n",
    "#                        usecols=['image_id', 'fold', 'target'], dtype={'fold': np.byte, 'target': np.byte})\n",
    "\n",
    "# df_test = pd.read_csv(f'../input/siim-isic-melanoma-classification/test.csv', index_col='image_name')\n",
    "\n",
    "# _ = df_folds.groupby('fold').target.hist(alpha=0.4)\n",
    "# df_folds.groupby('fold').target.mean().to_frame('ratio').T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.365975Z",
     "start_time": "2020-08-05T05:42:57.240590Z"
    }
   },
   "outputs": [],
   "source": [
    "resolution = 456\n",
    "input_res  = 512\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "#             A.JpegCompression(p=0.5),\n",
    "            A.Rotate(limit=45, p=1.0),\n",
    "            A.OneOf([\n",
    "                A.OpticalDistortion(),\n",
    "                A.GridDistortion(),\n",
    "                A.IAAPiecewiseAffine(),\n",
    "            ]),\n",
    "            A.RandomSizedCrop(min_max_height=(int(resolution*0.7), input_res),\n",
    "                              height=resolution, width=resolution, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.GaussianBlur(p=0.3),\n",
    "            A.OneOf([\n",
    "                A.RandomBrightnessContrast(),   \n",
    "                A.HueSaturationValue(),\n",
    "            ]),\n",
    "            A.Cutout(num_holes=8, max_h_size=resolution//8, max_w_size=resolution//8, fill_value=0, p=0.3),\n",
    "#             A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_fe_transforms():\n",
    "    return A.Compose([\n",
    "            A.CenterCrop(height=resolution, width=resolution, p=1.0),\n",
    "#             A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return A.Compose([\n",
    "            A.CenterCrop(height=resolution, width=resolution, p=1.0),\n",
    "#             A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)\n",
    "\n",
    "def get_tta_transforms():\n",
    "    return A.Compose([\n",
    "#             A.JpegCompression(p=0.5),\n",
    "            A.CenterCrop(height=resolution, width=resolution, p=1.0),\n",
    "#             A.RandomSizedCrop(min_max_height=(int(resolution*0.9), int(resolution*1.1)),\n",
    "#                               height=resolution, width=resolution, p=1.0),\n",
    "#             A.HorizontalFlip(p=0.5),\n",
    "#             A.VerticalFlip(p=0.5),\n",
    "#             A.Transpose(p=0.5),\n",
    "#             A.Normalize(),\n",
    "            ToTensorV2(),\n",
    "        ], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.457895Z",
     "start_time": "2020-08-05T05:42:57.368349Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, labels=None, transforms=None, mode=\"image\"):\n",
    "        super().__init__()\n",
    "#         self.path = path\n",
    "        self.df = df\n",
    "        self.image_ids = df.index.values\n",
    "        self.data_paths = df.data_path.values\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_id = self.image_ids[idx]\n",
    "        data_path = self.data_paths[idx]\n",
    "        image = cv2.imread(f'{data_path}/{image_id}.jpg', cv2.IMREAD_COLOR)\n",
    "#         print(f'{data_path}/{image_id}.jpg')\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(image=image)\n",
    "            image  = sample['image']\n",
    "            image = image.float()\n",
    "            \n",
    "\n",
    "        label = self.labels[idx] if self.labels is not None else 0.5\n",
    "\n",
    "        if self.mode==\"image\":\n",
    "            return image, label\n",
    "        else: \n",
    "            # self.mode==\"full\"\n",
    "            # imageとtable合わせて学習する場合\n",
    "            x = self.df.loc[image_id, FEATURES]\n",
    "            x = torch.tensor(x).float()\n",
    "            return image, x, label\n",
    "            \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def get_labels(self):\n",
    "        return list(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.603759Z",
     "start_time": "2020-08-05T05:42:57.460778Z"
    }
   },
   "outputs": [],
   "source": [
    "ds_train = ImageDataset(\n",
    "#     path=TRAIN_ROOT_PATH,\n",
    "    df=df_train[df_train['fold'] != fold_number],\n",
    "    labels=df_train[df_train['fold'] != fold_number].target.values,\n",
    "    transforms=get_train_transforms(),\n",
    ")\n",
    "\n",
    "ds_val = ImageDataset(\n",
    "#     path=TRAIN_ROOT_PATH,\n",
    "    # 外部データは除く\n",
    "    df=df_train[(df_train['fold'] == fold_number) & (df_train[\"data_path\"] ==TRAIN_ROOT_PATH)],\n",
    "    labels=df_train[(df_train['fold'] == fold_number) & (df_train[\"data_path\"] == TRAIN_ROOT_PATH)].target.values,\n",
    "    transforms=get_valid_transforms(),\n",
    ")\n",
    "\n",
    "ds_test = ImageDataset(\n",
    "#     path=TEST_ROOT_PATH,\n",
    "    df=df_test,\n",
    "    transforms=get_tta_transforms(),\n",
    ")\n",
    "\n",
    "ds_train2 = ImageDataset(\n",
    "#     path=TRAIN_ROOT_PATH,\n",
    "    df=df_train[df_train['fold'] != fold_number],\n",
    "    labels=df_train[df_train['fold'] != fold_number].target.values,\n",
    "    transforms=get_fe_transforms(),\n",
    "    mode = \"full\"\n",
    ")\n",
    "\n",
    "ds_val2 = ImageDataset(\n",
    "#     path=TRAIN_ROOT_PATH,\n",
    "    # 外部データは除く\n",
    "    df=df_train[(df_train['fold'] == fold_number) & (df_train[\"data_path\"] == TRAIN_ROOT_PATH)],\n",
    "    labels=df_train[(df_train['fold'] == fold_number) & (df_train[\"data_path\"] == TRAIN_ROOT_PATH)].target.values,\n",
    "    transforms=get_valid_transforms(),\n",
    "    mode = \"full\"\n",
    ")\n",
    "\n",
    "ds_test2 = ImageDataset(\n",
    "#     path=TEST_ROOT_PATH,\n",
    "    df=df_test,\n",
    "    transforms=get_tta_transforms(),\n",
    "    mode = \"full\"\n",
    ")\n",
    "\n",
    "ds_test_tta = ImageDataset(\n",
    "#     path=TEST_ROOT_PATH,\n",
    "    df=df_test,\n",
    "    transforms=get_train_transforms(),\n",
    "    mode = \"full\"\n",
    ")\n",
    "\n",
    "\n",
    "# del df_train\n",
    "# len(ds_train), len(ds_val), len(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.644142Z",
     "start_time": "2020-08-05T05:42:57.605497Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConcatModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,image_model,  ds_train, ds_val,ds_test,  batch_size=64,):\n",
    "            \n",
    "        super(ConcatModel, self).__init__()\n",
    "        \n",
    "        self.image_model = image_model\n",
    "        self.ds_train = ds_train\n",
    "        self.ds_val = ds_val\n",
    "        self.ds_test = ds_test\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = len(FEATURES)\n",
    "        self.val_logloss = list()\n",
    "        self.val_auc = list()\n",
    "            \n",
    "        # テーブルデータ用\n",
    "        self.layer1_1 = torch.nn.Linear(len(FEATURES), 64)     \n",
    "        self.layer1_2 = torch.nn.Linear(64, 16)\n",
    "        \n",
    "        #　 結合データ用\n",
    "        self.layer2_1 = torch.nn.Linear(self.image_model.n_map_features + self.layer1_2.out_features, 1024)     \n",
    "        self.layer2_2 = torch.nn.Linear(1024, 512)\n",
    "        self.layer2_3 = torch.nn.Linear(512, 256)\n",
    "        self.fc = torch.nn.Linear(256, 1)\n",
    "        \n",
    "        self.val_losses = list()\n",
    "\n",
    "        \n",
    "    def forward(self, image, x):\n",
    "        \n",
    "        # 画像の特徴量抽出\n",
    "        self.image_model.eval()\n",
    "        with torch.no_grad():\n",
    "            x1 = self.image_model(image, feature_extract=True) \n",
    "        \n",
    "        # tableの特徴量抽出\n",
    "        x2 = self.table_forward(x)\n",
    "        \n",
    "        #　くっつける\n",
    "        x_cat = torch.cat([x1,x2], dim=1)\n",
    "        \n",
    "        outputs = self.concat_forward(x_cat)\n",
    "        \n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def table_forward(self, x):\n",
    "#         x = x.view(-1, self.input_dim)\n",
    "        # layer 1-1\n",
    "        x = self.layer1_1(x)\n",
    "        x = torch.relu(x)\n",
    "        # layer 1-2\n",
    "        x = self.layer1_2(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def concat_forward(self, x):\n",
    "#         x = x.view(-1, self.input_dim)\n",
    "        # layer 2-1\n",
    "        x = self.layer2_1(x)\n",
    "        x = torch.relu(x)\n",
    "        # layer 2-2\n",
    "        x = self.layer2_2(x)\n",
    "        x = torch.relu(x)\n",
    "        # layer 2-3\n",
    "        x = self.layer2_3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def loss_function(self, y_pred, y_true):\n",
    "        loss = nn.BCEWithLogitsLoss()\n",
    "        return loss(y_pred, y_true)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        image, x, y_true = train_batch\n",
    "        y_pred = self(image, x).flatten()\n",
    "        loss = self.loss_function(y_pred, y_true.type_as(y_pred))\n",
    "\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        image, x, y_true = val_batch\n",
    "        logits = self(image, x)\n",
    "        y_pred = logits.flatten()\n",
    "        probs = torch.sigmoid(logits)\n",
    "#         loss = self.loss_function(y_pred, y_true.type_as(y_pred))\n",
    "#         return {'val_batch_loss': loss, 'probs':probs, 'y_true':y_true}\n",
    "        return {'probs':probs, 'y_true':y_true}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # called at the end of the validation epoch\n",
    "        # outputs is an array with what you returned in validation_step for each batch\n",
    "        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \n",
    "        probs = torch.cat([out['probs'] for out in outputs], dim=0)\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        \n",
    "        y_true = torch.cat([out['y_true'] for out in outputs], dim=0)\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "        \n",
    "        self.val_predicts = probs  # Save prediction internally for easy access\n",
    "        auc_score = roc_auc_score(y_true, probs)\n",
    "        cross_entropy = log_loss(y_true, probs)\n",
    "        \n",
    "        tensorboard_logs = {'valid_logloss': cross_entropy, 'valid_auc':auc_score}\n",
    "        self.val_logloss.append(cross_entropy)\n",
    "        self.val_auc.append(auc_score)\n",
    "        return {'val_loss': cross_entropy, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        image, x, _ = batch\n",
    "\n",
    "        logits = self(image, x)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        return {'probs': probs}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        probs = torch.cat([out['probs'] for out in outputs], dim=0)\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        self.test_predicts = probs  # Save prediction internally for easy access\n",
    "        # We need to return something \n",
    "        return {'dummy_item': 0}\n",
    "    \n",
    "    def prepare_data(self): \n",
    "        pass\n",
    "    \n",
    "    def train_dataloader(self): \n",
    "        return DataLoader(self.ds_train, batch_size=batch_size, num_workers=8, shuffle=True) \n",
    "\n",
    "    def val_dataloader(self): \n",
    "        return DataLoader(self.ds_val, batch_size=batch_size, num_workers=8) \n",
    "\n",
    "    def test_dataloader(self): \n",
    "        return DataLoader(self.ds_test, batch_size=batch_size, num_workers=8) \n",
    "\n",
    "    def configure_optimizers(self): \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5) \n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T05:42:57.747297Z",
     "start_time": "2020-08-05T05:42:57.647311Z"
    }
   },
   "outputs": [],
   "source": [
    "class MelanomaModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, ds_train, ds_val, ds_test, output_dim=None):\n",
    "            \n",
    "        super(MelanomaModel, self).__init__()\n",
    "        \n",
    "        self.ds_train = ds_train\n",
    "        self.ds_val = ds_val\n",
    "        self.ds_test = ds_test\n",
    "        self.val_logloss = list()\n",
    "        self.val_auc = list()\n",
    "\n",
    "#         resnet\n",
    "        self.net = models.resnet18(pretrained=True)\n",
    "        self.n_map_features = list(self.net.children())[-1].in_features\n",
    "        self.fc = nn.Linear(in_features=self.net.fc.in_features, out_features=1)\n",
    "        self.net.fc = nn.Identity()\n",
    "        \n",
    "#     #efficientnet\n",
    "#         self.net = ptcv_get_model(\"efficientnet_b2b\", pretrained=True)\n",
    "#         self.n_map_features = self.net.output.fc.in_features\n",
    "#         self.fc = nn.Linear(in_features=self.net.output.fc.in_features, out_features=1)\n",
    "#         self.net.output.fc = nn.Identity()\n",
    "\n",
    "        \n",
    "    def forward(self, x, feature_extract=False):\n",
    "        x = self.net(x)\n",
    "        if feature_extract:\n",
    "            return x\n",
    "        else:\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "    \n",
    "    def loss_function(self, y_pred, y_true):\n",
    "        loss = nn.BCEWithLogitsLoss()\n",
    "        return loss(y_pred, y_true)\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x, y_true = train_batch\n",
    "        y_pred = self(x).flatten()\n",
    "        loss = self.loss_function(y_pred, y_true.type_as(y_pred))\n",
    "\n",
    "        logs = {'train_loss': loss}\n",
    "        return {'loss': loss, 'log': logs}\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y_true = val_batch\n",
    "        logits = self(x)\n",
    "        y_pred = logits.flatten()\n",
    "        probs = torch.sigmoid(logits)\n",
    "#         loss = self.loss_function(y_pred, y_true.type_as(y_pred))\n",
    "#         return {'val_batch_loss': loss, 'probs':probs, 'y_true':y_true}\n",
    "        return {'probs':probs, 'y_true':y_true}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # called at the end of the validation epoch\n",
    "        # outputs is an array with what you returned in validation_step for each batch\n",
    "        # outputs = [{'loss': batch_0_loss}, {'loss': batch_1_loss}, ..., {'loss': batch_n_loss}] \n",
    "        probs = torch.cat([out['probs'] for out in outputs], dim=0)\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        \n",
    "        y_true = torch.cat([out['y_true'] for out in outputs], dim=0)\n",
    "        y_true = y_true.detach().cpu().numpy()\n",
    "        \n",
    "        self.val_predicts = probs  # Save prediction internally for easy access\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        auc_score = roc_auc_score(y_true, probs)\n",
    "        cross_entropy = log_loss(y_true, probs)\n",
    "        \n",
    "        tensorboard_logs = {'valid_logloss': cross_entropy, 'valid_auc':auc_score}\n",
    "        self.val_logloss.append(cross_entropy)\n",
    "        self.val_auc.append(auc_score)\n",
    "        return {'val_loss': cross_entropy, 'log': tensorboard_logs}\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "\n",
    "        logits = self(x)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        \n",
    "        return {'probs': probs}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        probs = torch.cat([out['probs'] for out in outputs], dim=0)\n",
    "        probs = probs.detach().cpu().numpy()\n",
    "        self.test_predicts = probs  # Save prediction internally for easy access\n",
    "        # We need to return something \n",
    "        return {'dummy_item': 0}\n",
    "    \n",
    "    \n",
    "    def prepare_data(self): \n",
    "        pass\n",
    "    \n",
    "    def train_dataloader(self): \n",
    "        return DataLoader(self.ds_train, batch_size=batch_size, num_workers=4, shuffle=True) \n",
    "\n",
    "    def val_dataloader(self): \n",
    "        return DataLoader(self.ds_val, batch_size=batch_size, num_workers=4) \n",
    "\n",
    "    def test_dataloader(self): \n",
    "        return DataLoader(self.ds_test, batch_size=batch_size, num_workers=4) \n",
    "\n",
    "    def configure_optimizers(self): \n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-5) \n",
    "        return optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:55.864Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name | Type   | Params\n",
      "--------------------------------\n",
      "0 | net  | ResNet | 11 M  \n",
      "1 | fc   | Linear | 513   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875b6c614a664785a0e8ca0be4acbb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00000: val_loss reached 0.13329 (best 0.13329), saving model to ../checkpoints/fold0_08051442/CNN/epoch=0.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss reached 0.08926 (best 0.08926), saving model to ../checkpoints/fold0_08051442/CNN/epoch=1.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss reached 0.09117 (best 0.08926), saving model to ../checkpoints/fold0_08051442/CNN/epoch=2.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_loss reached 0.07645 (best 0.07645), saving model to ../checkpoints/fold0_08051442/CNN/epoch=3.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: val_loss reached 0.07760 (best 0.07645), saving model to ../checkpoints/fold0_08051442/CNN/epoch=4.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_loss reached 0.07753 (best 0.07645), saving model to ../checkpoints/fold0_08051442/CNN/epoch=5.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_loss reached 0.07657 (best 0.07645), saving model to ../checkpoints/fold0_08051442/CNN/epoch=6.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_loss  was not in top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss reached 0.07339 (best 0.07339), saving model to ../checkpoints/fold0_08051442/CNN/epoch=8.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_loss reached 0.07506 (best 0.07339), saving model to ../checkpoints/fold0_08051442/CNN/epoch=9.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_loss reached 0.07281 (best 0.07281), saving model to ../checkpoints/fold0_08051442/CNN/epoch=10.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_loss reached 0.07080 (best 0.07080), saving model to ../checkpoints/fold0_08051442/CNN/epoch=11.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_loss reached 0.07101 (best 0.07080), saving model to ../checkpoints/fold0_08051442/CNN/epoch=12.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss reached 0.06850 (best 0.06850), saving model to ../checkpoints/fold0_08051442/CNN/epoch=13.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_loss reached 0.07129 (best 0.06850), saving model to ../checkpoints/fold0_08051442/CNN/epoch=14.ckpt as top 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_loss reached 0.07053 (best 0.06850), saving model to ../checkpoints/fold0_08051442/CNN/epoch=15.ckpt as top 4\n"
     ]
    }
   ],
   "source": [
    "ckpt_path1 = f\"{CKPT_PATH}/CNN\"\n",
    "log_path1 = f\"{LOG_PATH}/CNN\"\n",
    "os.makedirs(log_path1, exist_ok=True)\n",
    "os.makedirs(ckpt_path1, exist_ok=True)\n",
    "\n",
    "tb_log = TensorBoardLogger(save_dir = f\"{LOG_PATH}/CNN\")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=ckpt_path1,\n",
    "    save_top_k=4,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=10,\n",
    "   verbose=True,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "# train\n",
    "model = MelanomaModel(ds_train, ds_val, ds_test) \n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10000, logger=tb_log, checkpoint_callback=checkpoint_callback,\n",
    "                     early_stop_callback=early_stop_callback, gpus=gpus, distributed_backend='dp', num_sanity_val_steps=0)\n",
    "\n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:55.920Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_path2 = f\"{CKPT_PATH}/MLP\"\n",
    "log_path2 = f\"{LOG_PATH}/MLP\"\n",
    "os.makedirs(log_path2, exist_ok=True)\n",
    "os.makedirs(ckpt_path2, exist_ok=True)\n",
    "\n",
    "tb_log2 = TensorBoardLogger(save_dir = f\"{LOG_PATH}/MLP\")\n",
    "\n",
    "checkpoint_callback2 = ModelCheckpoint(\n",
    "    filepath=ckpt_path2,\n",
    "    save_top_k=4,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "early_stop_callback2 = EarlyStopping(\n",
    "   monitor='val_loss',\n",
    "   min_delta=0.00,\n",
    "   patience=10,\n",
    "   verbose=True,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "concat_model = ConcatModel(model, ds_train2, ds_val2, ds_test2)\n",
    "trainer2 = pl.Trainer(max_epochs=10000, logger=tb_log2, checkpoint_callback=checkpoint_callback2,\n",
    "                     early_stop_callback=early_stop_callback2, gpus=gpus, distributed_backend='dp', num_sanity_val_steps=0)\n",
    "\n",
    "\n",
    "trainer2.fit(concat_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:55.956Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer2.test(concat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:55.984Z"
    }
   },
   "outputs": [],
   "source": [
    "### TTA\n",
    "# preds_list = list()\n",
    "\n",
    "# for i in range(10):\n",
    "#     trainer2.test(concat_model)\n",
    "#     preds_list.append(concat_model.test_predicts)\n",
    "\n",
    "# preds_arr = np.array(preds_list).squeeze()\n",
    "# new_preds = preds_arr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:57.763Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f\"{DATA_PATH}/sample_submission.csv\")\n",
    "submission[\"target\"] = concat_model.test_predicts.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:58.446Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f\"{ROOT_PATH}/output/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T05:42:58.595Z"
    }
   },
   "outputs": [],
   "source": [
    "concat_model.val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
